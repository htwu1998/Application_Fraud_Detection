{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "numerical-celtic",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "several-certification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T19:52:35.226076Z",
     "start_time": "2021-03-19T19:52:35.217056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD DURATION: 0:00:00.000889\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import time \n",
    "import calendar\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.stats as sps\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import keras\n",
    "\n",
    "\n",
    "print('LOAD DURATION:',datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-script",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accredited-tonight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T19:53:14.504137Z",
     "start_time": "2021-03-19T19:52:37.272357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33 s, sys: 4.08 s, total: 37.1 s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the data\n",
    "data = pd.read_csv('400_var.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-morgan",
   "metadata": {},
   "source": [
    "### Selected Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-madison",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:52:35.568289Z",
     "start_time": "2021-03-18T06:52:35.552522Z"
    }
   },
   "outputs": [],
   "source": [
    "score['rank_ks'] = score['ks'].rank(ascending = True)\n",
    "score['rank_FDR'] = score['FDR at 3%'].rank(ascending = True)\n",
    "\n",
    "score['average_rank'] = (score['rank_ks'] + score['rank_FDR']) / 2\n",
    "score.sort_values(by=['average_rank'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-description",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:52:35.573911Z",
     "start_time": "2021-03-18T06:52:35.570967Z"
    }
   },
   "outputs": [],
   "source": [
    "selected = list(score[:101]['Variable'])\n",
    "selected.append('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-damages",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:52:36.869500Z",
     "start_time": "2021-03-18T06:52:35.576566Z"
    }
   },
   "outputs": [],
   "source": [
    "df_s = data[selected].copy()\n",
    "df_s['date'] = pd.to_datetime(df_s.date)\n",
    "selection = df_s[(df_s.date > '2016-01-14')&(df_s.date < '2016-11-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-nickname",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:52:37.239430Z",
     "start_time": "2021-03-18T06:52:36.871486Z"
    }
   },
   "outputs": [],
   "source": [
    "select_x = selection.drop(columns=['fraud_label', 'date'])\n",
    "select_y = selection['fraud_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-florist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:39:54.572548Z",
     "start_time": "2021-03-18T06:25:46.523537Z"
    }
   },
   "outputs": [],
   "source": [
    "# do not run both RFECV in one setting\n",
    "# n_jobs = -1 can only be used once \n",
    "model = LogisticRegression(penalty='l2', class_weight='balanced')\n",
    "rfecv = RFECV(estimator=model, step=1, cv=2, verbose=2, n_jobs=-1, scoring=\"roc_auc\")\n",
    "rfecv.fit(select_x, select_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-brass",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:40:36.287185Z",
     "start_time": "2021-03-18T06:40:36.087421Z"
    }
   },
   "outputs": [],
   "source": [
    "var_select_1 = pd.DataFrame(sorted(zip(map(lambda x: round(x,3), rfecv.ranking_), select_x.columns)),\n",
    "                            columns = ['ranking', 'variable'])\n",
    "print(var_select_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-professional",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:48:24.625725Z",
     "start_time": "2021-03-18T06:48:24.486407Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation socre (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_)+1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-variation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:52:37.248194Z",
     "start_time": "2021-03-18T06:52:37.241695Z"
    }
   },
   "outputs": [],
   "source": [
    "var_select_manual = [\n",
    " 'address_count_0',\n",
    " 'address_count_0_by_30',\n",
    " 'address_count_0_by_7',\n",
    " 'address_count_1',\n",
    " 'address_count_1_by_14',\n",
    " 'address_count_1_by_7',\n",
    " 'address_count_3',\n",
    " 'address_count_30',\n",
    " 'address_unique_count_for_name_dob_1',\n",
    " 'address_unique_count_for_name_dob_14',\n",
    " 'address_unique_count_for_name_dob_3',\n",
    " 'address_unique_count_for_name_dob_30',\n",
    " 'address_unique_count_for_name_dob_7',\n",
    " 'address_unique_count_for_ssn_1',\n",
    " 'address_unique_count_for_ssn_14',\n",
    " 'address_unique_count_for_ssn_3',\n",
    " 'address_unique_count_for_ssn_30',\n",
    " 'address_unique_count_for_ssn_7',\n",
    " 'fulladdress_count_0',\n",
    " 'fulladdress_count_0_by_14',\n",
    " 'fulladdress_count_0_by_3',\n",
    " 'fulladdress_count_1',\n",
    " 'fulladdress_count_14',\n",
    " 'fulladdress_count_1_by_30',\n",
    " 'fulladdress_count_7',\n",
    " 'fulladdress_day_since',\n",
    " 'fulladdress_homephone_count_0_by_14',\n",
    " 'fulladdress_homephone_count_0_by_30',\n",
    " 'fulladdress_homephone_count_3',\n",
    " 'fulladdress_homephone_count_7',\n",
    " 'fulladdress_homephone_day_since',\n",
    " 'homephone_count_14',\n",
    " 'homephone_count_3',\n",
    " 'homephone_count_7',\n",
    " 'homephone_unique_count_for_name_dob_3',\n",
    " 'homephone_unique_count_for_name_dob_7',\n",
    " 'homephone_unique_count_for_ssn_3',\n",
    " 'homephone_unique_count_for_ssn_7',\n",
    " 'name_count_14',\n",
    " 'name_count_30',\n",
    " 'name_count_7',\n",
    " 'name_dob_count_0_by_14',\n",
    " 'name_dob_count_0_by_30',\n",
    " 'name_dob_count_7',\n",
    " 'name_dob_day_since',\n",
    " 'name_dob_unique_count_for_address_30',\n",
    " 'name_dob_unique_count_for_homephone_30',\n",
    " 'ssn_count_0_by_14',\n",
    " 'ssn_count_0_by_30',\n",
    " 'ssn_count_7',\n",
    " 'ssn_day_since',\n",
    " 'ssn_dob_count_0_by_14',\n",
    " 'ssn_dob_count_0_by_30',\n",
    " 'ssn_dob_count_7',\n",
    " 'ssn_dob_day_since',\n",
    " 'ssn_name_count_0_by_14',\n",
    " 'ssn_name_count_0_by_30',\n",
    " 'ssn_name_count_7',\n",
    " 'ssn_name_day_since',\n",
    " 'ssn_name_dob_count_14',\n",
    " 'ssn_name_dob_count_30',\n",
    " 'ssn_name_dob_count_7',\n",
    " 'ssn_name_dob_day_since'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-trinity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T06:52:37.477407Z",
     "start_time": "2021-03-18T06:52:37.249929Z"
    }
   },
   "outputs": [],
   "source": [
    "select_x_2 = selection[var_select_manual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-confidentiality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:02:59.300435Z",
     "start_time": "2021-03-18T06:52:48.927763Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = DecisionTreeClassifier(class_weight='balanced')\n",
    "rfecv2 = RFECV(estimator=model2, step=1, cv=2, verbose=2, n_jobs=-1, scoring=\"roc_auc\")\n",
    "rfecv2.fit(select_x_2, select_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-woman",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:05:53.471384Z",
     "start_time": "2021-03-18T07:05:53.460383Z"
    }
   },
   "outputs": [],
   "source": [
    "var_select_2 = pd.DataFrame(sorted(zip(map(lambda x: round(x,3), rfecv2.ranking_), select_x_2.columns)),\n",
    "                            columns = ['ranking', 'variable'])\n",
    "print(var_select_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fuzzy-beaver",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T19:53:53.345305Z",
     "start_time": "2021-03-19T19:53:53.337097Z"
    }
   },
   "outputs": [],
   "source": [
    "var_list = [\n",
    " 'address_count_0_by_14',\n",
    " 'address_count_0_by_30',\n",
    " 'address_count_14',\n",
    " 'address_count_30',\n",
    " 'address_count_7',\n",
    " 'address_unique_count_for_name_dob_14',\n",
    " 'address_unique_count_for_name_dob_30',\n",
    " 'address_unique_count_for_ssn_14',\n",
    " 'address_unique_count_for_ssn_30',\n",
    " 'fulladdress_count_0_by_14',\n",
    " 'fulladdress_count_14',\n",
    " 'fulladdress_count_14',\n",
    " 'fulladdress_count_30',\n",
    " 'fulladdress_day_since',\n",
    " 'fulladdress_homephone_count_0_by_30',\n",
    " 'fulladdress_homephone_count_14',\n",
    " 'fulladdress_homephone_count_30',\n",
    " 'fulladdress_homephone_day_since',\n",
    " 'name_dob_count_0_by_14',\n",
    " 'name_dob_count_0_by_30',\n",
    " 'ssn_count_30',\n",
    " 'ssn_dob_count_14',\n",
    " 'ssn_dob_count_30',\n",
    " 'ssn_dob_day_since',\n",
    " 'ssn_lastname_count_30',\n",
    " 'ssn_name_dob_day_since',\n",
    " 'ssn_day_since',\n",
    " 'address_day_since',\n",
    " 'name_dob_day_since',\n",
    " 'fulladdress_count_0_by_7',\n",
    " 'date',\n",
    " 'fraud_label'\n",
    "]\n",
    "\n",
    "new_list = [\n",
    " 'address_count_30',\n",
    " 'fulladdress_day_since',\n",
    " 'name_dob_unique_count_for_homephone_30',\n",
    " 'homephone_unique_count_for_ssn_3',\n",
    " 'ssn_dob_day_since',\n",
    " 'address_unique_count_for_ssn_14',\n",
    " 'ssn_day_since',\n",
    " 'homephone_count_14',\n",
    " 'fulladdress_homephone_day_since',\n",
    " 'name_dob_day_since',\n",
    " 'homephone_unique_count_for_ssn_7',\n",
    " 'ssn_name_day_since',\n",
    " 'name_count_30',\n",
    " 'homephone_unique_count_for_name_dob_3',\n",
    " 'ssn_name_dob_day_since',\n",
    " 'homephone_count_7',\n",
    " 'name_count_14',\n",
    " 'homephone_count_3',\n",
    " 'name_count_7',\n",
    " 'homephone_unique_count_for_name_dob_7',\n",
    " 'address_count_1_by_7',\n",
    " 'address_count_1_by_14',\n",
    " 'address_unique_count_for_ssn_30',\n",
    " 'address_unique_count_for_name_dob_3',\n",
    " 'address_count_0_by_30',\n",
    " 'address_unique_count_for_name_dob_30',\n",
    " 'address_count_0_by_7',\n",
    " 'name_dob_unique_count_for_address_30',\n",
    " 'address_unique_count_for_name_dob_7',\n",
    " 'ssn_count_7',\n",
    " 'date',\n",
    " 'fraud_label'\n",
    "]\n",
    "\n",
    "combined_list = [\n",
    " 'address_count_30',\n",
    " 'fulladdress_day_since',\n",
    " 'name_dob_unique_count_for_homephone_30',\n",
    " 'homephone_unique_count_for_ssn_3',\n",
    " 'ssn_dob_day_since',\n",
    " 'address_unique_count_for_name_dob_7',\n",
    " 'fulladdress_homephone_day_since',\n",
    " 'ssn_name_dob_day_since',\n",
    " 'ssn_count_30',\n",
    " 'address_unique_count_for_name_dob_30',\n",
    " 'address_unique_count_for_ssn_30',\n",
    " 'address_count_1_by_14',\n",
    " 'ssn_lastname_count_30',\n",
    " 'address_count_0_by_7',\n",
    " 'address_unique_count_for_name_dob_3',\n",
    " 'name_dob_unique_count_for_address_30',\n",
    " 'ssn_count_7',\n",
    " 'address_count_0_by_30',\n",
    " 'address_count_1_by_7',\n",
    " 'ssn_dob_count_14',\n",
    " 'name_dob_count_0_by_14',\n",
    " 'fulladdress_homephone_count_14',\n",
    " 'name_dob_count_0_by_30',\n",
    " 'fulladdress_homephone_count_30',\n",
    " 'ssn_dob_count_30',\n",
    " 'date',\n",
    " 'fraud_label'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "combined-sauce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T08:03:23.674998Z",
     "start_time": "2021-03-20T08:03:21.074541Z"
    }
   },
   "outputs": [],
   "source": [
    "# create datasets with 30 selected features\n",
    "df = data[combined_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alert-adapter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T08:03:31.311633Z",
     "start_time": "2021-03-20T08:03:30.957655Z"
    }
   },
   "outputs": [],
   "source": [
    "# separate train, test, oot data\n",
    "df['date'] = pd.to_datetime(df.date)\n",
    "\n",
    "#train_test\n",
    "train_test = df[(df.date > '2016-01-14')&(df.date < '2016-11-01')]\n",
    "\n",
    "oot_data = df[df.date >= '2016-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "irish-statistics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T08:03:32.217371Z",
     "start_time": "2021-03-20T08:03:32.075486Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_test.drop(columns=['fraud_label', 'date'])\n",
    "y = train_test[['fraud_label']]\n",
    "\n",
    "oot_x = oot_data.drop(columns=['fraud_label', 'date'])\n",
    "oot_y = oot_data['fraud_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "economic-integral",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T08:03:48.250921Z",
     "start_time": "2021-03-20T08:03:47.640399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_count_30</th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_unique_count_for_homephone_30</th>\n",
       "      <th>homephone_unique_count_for_ssn_3</th>\n",
       "      <th>ssn_dob_day_since</th>\n",
       "      <th>address_unique_count_for_name_dob_7</th>\n",
       "      <th>fulladdress_homephone_day_since</th>\n",
       "      <th>ssn_name_dob_day_since</th>\n",
       "      <th>ssn_count_30</th>\n",
       "      <th>address_unique_count_for_name_dob_30</th>\n",
       "      <th>...</th>\n",
       "      <th>name_dob_unique_count_for_address_30</th>\n",
       "      <th>ssn_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>address_count_1_by_7</th>\n",
       "      <th>ssn_dob_count_14</th>\n",
       "      <th>name_dob_count_0_by_14</th>\n",
       "      <th>fulladdress_homephone_count_14</th>\n",
       "      <th>name_dob_count_0_by_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "      <td>794996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.080105</td>\n",
       "      <td>326.637368</td>\n",
       "      <td>1.020345</td>\n",
       "      <td>1.447595</td>\n",
       "      <td>332.680089</td>\n",
       "      <td>1.036903</td>\n",
       "      <td>331.207869</td>\n",
       "      <td>332.822667</td>\n",
       "      <td>1.050981</td>\n",
       "      <td>1.053410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019843</td>\n",
       "      <td>1.025737</td>\n",
       "      <td>29.342400</td>\n",
       "      <td>6.960817</td>\n",
       "      <td>1.031863</td>\n",
       "      <td>13.892903</td>\n",
       "      <td>1.034473</td>\n",
       "      <td>29.573966</td>\n",
       "      <td>1.049368</td>\n",
       "      <td>1.046209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.669916</td>\n",
       "      <td>98.866112</td>\n",
       "      <td>0.456040</td>\n",
       "      <td>0.857291</td>\n",
       "      <td>91.609103</td>\n",
       "      <td>0.588851</td>\n",
       "      <td>93.407625</td>\n",
       "      <td>91.423906</td>\n",
       "      <td>0.503758</td>\n",
       "      <td>0.646476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455393</td>\n",
       "      <td>0.442692</td>\n",
       "      <td>3.242724</td>\n",
       "      <td>0.376599</td>\n",
       "      <td>0.461563</td>\n",
       "      <td>0.897749</td>\n",
       "      <td>0.482971</td>\n",
       "      <td>2.573872</td>\n",
       "      <td>0.508366</td>\n",
       "      <td>0.487080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       address_count_30  fulladdress_day_since  \\\n",
       "count     794996.000000          794996.000000   \n",
       "mean           1.080105             326.637368   \n",
       "std            0.669916              98.866112   \n",
       "min            1.000000               0.000000   \n",
       "25%            1.000000             365.000000   \n",
       "50%            1.000000             365.000000   \n",
       "75%            1.000000             365.000000   \n",
       "max           30.000000             365.000000   \n",
       "\n",
       "       name_dob_unique_count_for_homephone_30  \\\n",
       "count                           794996.000000   \n",
       "mean                                 1.020345   \n",
       "std                                  0.456040   \n",
       "min                                  1.000000   \n",
       "25%                                  1.000000   \n",
       "50%                                  1.000000   \n",
       "75%                                  1.000000   \n",
       "max                                 34.000000   \n",
       "\n",
       "       homephone_unique_count_for_ssn_3  ssn_dob_day_since  \\\n",
       "count                     794996.000000      794996.000000   \n",
       "mean                           1.447595         332.680089   \n",
       "std                            0.857291          91.609103   \n",
       "min                            1.000000           0.000000   \n",
       "25%                            1.000000         365.000000   \n",
       "50%                            1.000000         365.000000   \n",
       "75%                            2.000000         365.000000   \n",
       "max                           30.000000         365.000000   \n",
       "\n",
       "       address_unique_count_for_name_dob_7  fulladdress_homephone_day_since  \\\n",
       "count                        794996.000000                    794996.000000   \n",
       "mean                              1.036903                       331.207869   \n",
       "std                               0.588851                        93.407625   \n",
       "min                               1.000000                         0.000000   \n",
       "25%                               1.000000                       365.000000   \n",
       "50%                               1.000000                       365.000000   \n",
       "75%                               1.000000                       365.000000   \n",
       "max                              30.000000                       365.000000   \n",
       "\n",
       "       ssn_name_dob_day_since   ssn_count_30  \\\n",
       "count           794996.000000  794996.000000   \n",
       "mean               332.822667       1.050981   \n",
       "std                 91.423906       0.503758   \n",
       "min                  0.000000       1.000000   \n",
       "25%                365.000000       1.000000   \n",
       "50%                365.000000       1.000000   \n",
       "75%                365.000000       1.000000   \n",
       "max                365.000000      34.000000   \n",
       "\n",
       "       address_unique_count_for_name_dob_30  ...  \\\n",
       "count                         794996.000000  ...   \n",
       "mean                               1.053410  ...   \n",
       "std                                0.646476  ...   \n",
       "min                                1.000000  ...   \n",
       "25%                                1.000000  ...   \n",
       "50%                                1.000000  ...   \n",
       "75%                                1.000000  ...   \n",
       "max                               30.000000  ...   \n",
       "\n",
       "       name_dob_unique_count_for_address_30    ssn_count_7  \\\n",
       "count                         794996.000000  794996.000000   \n",
       "mean                               1.019843       1.025737   \n",
       "std                                0.455393       0.442692   \n",
       "min                                1.000000       1.000000   \n",
       "25%                                1.000000       1.000000   \n",
       "50%                                1.000000       1.000000   \n",
       "75%                                1.000000       1.000000   \n",
       "max                               34.000000      34.000000   \n",
       "\n",
       "       address_count_0_by_30  address_count_1_by_7  ssn_dob_count_14  \\\n",
       "count          794996.000000         794996.000000     794996.000000   \n",
       "mean               29.342400              6.960817          1.031863   \n",
       "std                 3.242724              0.376599          0.461563   \n",
       "min                 1.304348              0.583333          1.000000   \n",
       "25%                30.000000              7.000000          1.000000   \n",
       "50%                30.000000              7.000000          1.000000   \n",
       "75%                30.000000              7.000000          1.000000   \n",
       "max                30.000000              7.000000         34.000000   \n",
       "\n",
       "       name_dob_count_0_by_14  fulladdress_homephone_count_14  \\\n",
       "count           794996.000000                   794996.000000   \n",
       "mean                13.892903                        1.034473   \n",
       "std                  0.897749                        0.482971   \n",
       "min                  0.636364                        1.000000   \n",
       "25%                 14.000000                        1.000000   \n",
       "50%                 14.000000                        1.000000   \n",
       "75%                 14.000000                        1.000000   \n",
       "max                 14.000000                       29.000000   \n",
       "\n",
       "       name_dob_count_0_by_30  fulladdress_homephone_count_30  \\\n",
       "count           794996.000000                   794996.000000   \n",
       "mean                29.573966                        1.049368   \n",
       "std                  2.573872                        0.508366   \n",
       "min                  1.363636                        1.000000   \n",
       "25%                 30.000000                        1.000000   \n",
       "50%                 30.000000                        1.000000   \n",
       "75%                 30.000000                        1.000000   \n",
       "max                 30.000000                       29.000000   \n",
       "\n",
       "       ssn_dob_count_30  \n",
       "count     794996.000000  \n",
       "mean           1.046209  \n",
       "std            0.487080  \n",
       "min            1.000000  \n",
       "25%            1.000000  \n",
       "50%            1.000000  \n",
       "75%            1.000000  \n",
       "max           34.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "prescribed-burke",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-20T08:05:42.256154Z",
     "start_time": "2021-03-20T08:05:42.102405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_count_30</th>\n",
       "      <th>fulladdress_day_since</th>\n",
       "      <th>name_dob_unique_count_for_homephone_30</th>\n",
       "      <th>homephone_unique_count_for_ssn_3</th>\n",
       "      <th>ssn_dob_day_since</th>\n",
       "      <th>address_unique_count_for_name_dob_7</th>\n",
       "      <th>fulladdress_homephone_day_since</th>\n",
       "      <th>ssn_name_dob_day_since</th>\n",
       "      <th>ssn_count_30</th>\n",
       "      <th>address_unique_count_for_name_dob_30</th>\n",
       "      <th>...</th>\n",
       "      <th>name_dob_unique_count_for_address_30</th>\n",
       "      <th>ssn_count_7</th>\n",
       "      <th>address_count_0_by_30</th>\n",
       "      <th>address_count_1_by_7</th>\n",
       "      <th>ssn_dob_count_14</th>\n",
       "      <th>name_dob_count_0_by_14</th>\n",
       "      <th>fulladdress_homephone_count_14</th>\n",
       "      <th>name_dob_count_0_by_30</th>\n",
       "      <th>fulladdress_homephone_count_30</th>\n",
       "      <th>ssn_dob_count_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "      <td>166493.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.078346</td>\n",
       "      <td>309.457359</td>\n",
       "      <td>1.024001</td>\n",
       "      <td>1.445670</td>\n",
       "      <td>317.560624</td>\n",
       "      <td>1.032602</td>\n",
       "      <td>315.568492</td>\n",
       "      <td>317.748776</td>\n",
       "      <td>1.055804</td>\n",
       "      <td>1.050999</td>\n",
       "      <td>...</td>\n",
       "      <td>1.023412</td>\n",
       "      <td>1.029815</td>\n",
       "      <td>29.342424</td>\n",
       "      <td>6.960674</td>\n",
       "      <td>1.035809</td>\n",
       "      <td>13.890628</td>\n",
       "      <td>1.034146</td>\n",
       "      <td>29.567146</td>\n",
       "      <td>1.049666</td>\n",
       "      <td>1.050417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.658196</td>\n",
       "      <td>106.544062</td>\n",
       "      <td>0.513705</td>\n",
       "      <td>0.872399</td>\n",
       "      <td>100.255284</td>\n",
       "      <td>0.545742</td>\n",
       "      <td>101.713377</td>\n",
       "      <td>100.089049</td>\n",
       "      <td>0.566275</td>\n",
       "      <td>0.632015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513159</td>\n",
       "      <td>0.500642</td>\n",
       "      <td>3.244908</td>\n",
       "      <td>0.378508</td>\n",
       "      <td>0.518074</td>\n",
       "      <td>0.913591</td>\n",
       "      <td>0.498664</td>\n",
       "      <td>2.603736</td>\n",
       "      <td>0.530106</td>\n",
       "      <td>0.544683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       address_count_30  fulladdress_day_since  \\\n",
       "count     166493.000000          166493.000000   \n",
       "mean           1.078346             309.457359   \n",
       "std            0.658196             106.544062   \n",
       "min            1.000000               0.000000   \n",
       "25%            1.000000             324.000000   \n",
       "50%            1.000000             365.000000   \n",
       "75%            1.000000             365.000000   \n",
       "max           30.000000             365.000000   \n",
       "\n",
       "       name_dob_unique_count_for_homephone_30  \\\n",
       "count                           166493.000000   \n",
       "mean                                 1.024001   \n",
       "std                                  0.513705   \n",
       "min                                  1.000000   \n",
       "25%                                  1.000000   \n",
       "50%                                  1.000000   \n",
       "75%                                  1.000000   \n",
       "max                                 29.000000   \n",
       "\n",
       "       homephone_unique_count_for_ssn_3  ssn_dob_day_since  \\\n",
       "count                     166493.000000      166493.000000   \n",
       "mean                           1.445670         317.560624   \n",
       "std                            0.872399         100.255284   \n",
       "min                            1.000000           0.000000   \n",
       "25%                            1.000000         365.000000   \n",
       "50%                            1.000000         365.000000   \n",
       "75%                            2.000000         365.000000   \n",
       "max                           32.000000         365.000000   \n",
       "\n",
       "       address_unique_count_for_name_dob_7  fulladdress_homephone_day_since  \\\n",
       "count                        166493.000000                    166493.000000   \n",
       "mean                              1.032602                       315.568492   \n",
       "std                               0.545742                       101.713377   \n",
       "min                               1.000000                         0.000000   \n",
       "25%                               1.000000                       365.000000   \n",
       "50%                               1.000000                       365.000000   \n",
       "75%                               1.000000                       365.000000   \n",
       "max                              30.000000                       365.000000   \n",
       "\n",
       "       ssn_name_dob_day_since   ssn_count_30  \\\n",
       "count           166493.000000  166493.000000   \n",
       "mean               317.748776       1.055804   \n",
       "std                100.089049       0.566275   \n",
       "min                  0.000000       1.000000   \n",
       "25%                365.000000       1.000000   \n",
       "50%                365.000000       1.000000   \n",
       "75%                365.000000       1.000000   \n",
       "max                365.000000      29.000000   \n",
       "\n",
       "       address_unique_count_for_name_dob_30  ...  \\\n",
       "count                         166493.000000  ...   \n",
       "mean                               1.050999  ...   \n",
       "std                                0.632015  ...   \n",
       "min                                1.000000  ...   \n",
       "25%                                1.000000  ...   \n",
       "50%                                1.000000  ...   \n",
       "75%                                1.000000  ...   \n",
       "max                               30.000000  ...   \n",
       "\n",
       "       name_dob_unique_count_for_address_30    ssn_count_7  \\\n",
       "count                         166493.000000  166493.000000   \n",
       "mean                               1.023412       1.029815   \n",
       "std                                0.513159       0.500642   \n",
       "min                                1.000000       1.000000   \n",
       "25%                                1.000000       1.000000   \n",
       "50%                                1.000000       1.000000   \n",
       "75%                                1.000000       1.000000   \n",
       "max                               29.000000      29.000000   \n",
       "\n",
       "       address_count_0_by_30  address_count_1_by_7  ssn_dob_count_14  \\\n",
       "count          166493.000000         166493.000000     166493.000000   \n",
       "mean               29.342424              6.960674          1.035809   \n",
       "std                 3.244908              0.378508          0.518074   \n",
       "min                 1.578947              0.700000          1.000000   \n",
       "25%                30.000000              7.000000          1.000000   \n",
       "50%                30.000000              7.000000          1.000000   \n",
       "75%                30.000000              7.000000          1.000000   \n",
       "max                30.000000              7.000000         29.000000   \n",
       "\n",
       "       name_dob_count_0_by_14  fulladdress_homephone_count_14  \\\n",
       "count           166493.000000                   166493.000000   \n",
       "mean                13.890628                        1.034146   \n",
       "std                  0.913591                        0.498664   \n",
       "min                  0.700000                        1.000000   \n",
       "25%                 14.000000                        1.000000   \n",
       "50%                 14.000000                        1.000000   \n",
       "75%                 14.000000                        1.000000   \n",
       "max                 14.000000                       30.000000   \n",
       "\n",
       "       name_dob_count_0_by_30  fulladdress_homephone_count_30  \\\n",
       "count           166493.000000                   166493.000000   \n",
       "mean                29.567146                        1.049666   \n",
       "std                  2.603736                        0.530106   \n",
       "min                  1.500000                        1.000000   \n",
       "25%                 30.000000                        1.000000   \n",
       "50%                 30.000000                        1.000000   \n",
       "75%                 30.000000                        1.000000   \n",
       "max                 30.000000                       30.000000   \n",
       "\n",
       "       ssn_dob_count_30  \n",
       "count     166493.000000  \n",
       "mean           1.050417  \n",
       "std            0.544683  \n",
       "min            1.000000  \n",
       "25%            1.000000  \n",
       "50%            1.000000  \n",
       "75%            1.000000  \n",
       "max           29.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oot_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-walker",
   "metadata": {},
   "source": [
    "### FDR@3% Calculation (LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "concerned-material",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T19:54:10.559643Z",
     "start_time": "2021-03-19T19:54:10.555122Z"
    }
   },
   "outputs": [],
   "source": [
    "# create functions to calculate fdr\n",
    "def fdr_cal(x_data, y_data, model_choice):\n",
    "    model = model_choice\n",
    "    pop = int(round(len(x_data)*0.03))\n",
    "    result = pd.DataFrame(model.predict_proba(x_data),columns=['prob_0', 'prob_1'])\n",
    "    temp = x_data.copy()\n",
    "    temp['fraud_label'] = y_data\n",
    "    temp['prob_1']= list(result.prob_1)\n",
    "    temp0 = temp.sort_values('prob_1', ascending=False)\n",
    "    temp1 = temp0.head(pop)\n",
    "    fdr = temp1.fraud_label.sum() / y_data.sum()\n",
    "    \n",
    "    return fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "synthetic-marsh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T19:54:11.185521Z",
     "start_time": "2021-03-19T19:54:11.183177Z"
    }
   },
   "outputs": [],
   "source": [
    "final_var = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "answering-broadcasting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T19:57:22.366969Z",
     "start_time": "2021-03-19T19:54:34.158220Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/haotian/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 58s, sys: 2min 55s, total: 20min 53s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a for loop to calculate all logreg FDR@3%\n",
    "\n",
    "# using KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "var_num = [5,10,15,20,25,30]\n",
    "train_fdr = []\n",
    "test_fdr = []\n",
    "oot_fdr = []\n",
    "\n",
    "fdr_table = pd.DataFrame(var_num, columns=['Number of Variables'])\n",
    "\n",
    "# loop through each setting for variables\n",
    "\n",
    "for num in var_num:\n",
    "    train_fdr_mlr = []\n",
    "    test_fdr_mlr = []\n",
    "    oot_fdr_mlr = []\n",
    "\n",
    "    cols = final_var[:num]\n",
    "    X_1 = X[cols]\n",
    "    X_oot = oot_x[cols]\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_1):\n",
    "        X_train, X_test = X_1.iloc[train_index,:], X_1.iloc[test_index,:]\n",
    "        y_train, y_test = y.iloc[train_index, :], y.iloc[test_index, :]\n",
    "        \n",
    "        mlr = LogisticRegression()\n",
    "        mlr.fit(X_train, y_train)\n",
    "        \n",
    "        fdr_train = fdr_cal(X_train, y_train, mlr)\n",
    "        fdr_test = fdr_cal(X_test, y_test, mlr)\n",
    "        fdr_oot = fdr_cal(X_oot, oot_y, mlr)\n",
    "        \n",
    "        train_fdr_mlr.append(fdr_train)\n",
    "        test_fdr_mlr.append(fdr_test)\n",
    "        oot_fdr_mlr.append(fdr_oot)\n",
    "        \n",
    "    train_fdr.append(np.mean(train_fdr_mlr))\n",
    "    test_fdr.append(np.mean(test_fdr_mlr))\n",
    "    oot_fdr.append(np.mean(oot_fdr_mlr))\n",
    "\n",
    "fdr_table['Train'] = train_fdr\n",
    "fdr_table['Test'] = test_fdr\n",
    "fdr_table['OOT'] = oot_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spoken-order",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T19:57:22.483161Z",
     "start_time": "2021-03-19T19:57:22.369455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Variables</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.472897</td>\n",
       "      <td>0.469605</td>\n",
       "      <td>0.453646</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.493447</td>\n",
       "      <td>0.492659</td>\n",
       "      <td>0.480302</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.507995</td>\n",
       "      <td>0.502294</td>\n",
       "      <td>0.480553</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.484128</td>\n",
       "      <td>0.481684</td>\n",
       "      <td>0.465298</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.496845</td>\n",
       "      <td>0.492098</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30</td>\n",
       "      <td>0.496628</td>\n",
       "      <td>0.493988</td>\n",
       "      <td>0.474518</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Variables     Train      Test       OOT                Model\n",
       "0                    5  0.472897  0.469605  0.453646  Logistic Regression\n",
       "1                   10  0.493447  0.492659  0.480302  Logistic Regression\n",
       "2                   15  0.507995  0.502294  0.480553  Logistic Regression\n",
       "3                   20  0.484128  0.481684  0.465298  Logistic Regression\n",
       "4                   25  0.496845  0.492098  0.475524  Logistic Regression\n",
       "5                   30  0.496628  0.493988  0.474518  Logistic Regression"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdr_table['Model'] = 'Logistic Regression'\n",
    "fdr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "racial-virus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T10:13:12.102166Z",
     "start_time": "2021-03-18T10:13:12.089623Z"
    }
   },
   "outputs": [],
   "source": [
    "fdr_table.to_excel('fdr_table.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-grace",
   "metadata": {},
   "source": [
    "### FDR@3% Calculation (Boosted Tree - GradientBoostingModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "requested-juice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T10:36:26.757835Z",
     "start_time": "2021-03-18T10:36:26.735237Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a table to store the data\n",
    "gbm_table = pd.DataFrame(columns=['# of Trees', 'Max Depth', 'Learning Rate'])\n",
    "num_tree = [100,200,500]\n",
    "max_depth = [1,2]\n",
    "learn_rate = [0.1, 0.01]\n",
    "\n",
    "\n",
    "i=0\n",
    "for lr in learn_rate:\n",
    "    for md in max_depth:\n",
    "        for num in num_tree:\n",
    "            gbm_table.loc[i,'# of Trees'] = num\n",
    "            gbm_table.loc[i,'Max Depth'] = md\n",
    "            gbm_table.loc[i,'Learning Rate'] = lr\n",
    "            i+=1\n",
    "\n",
    "for col in ['# of Trees', 'Max Depth', 'Learning Rate']:\n",
    "    gbm_table[col] = gbm_table[col].astype('object')\n",
    "\n",
    "gbm_table['Train'] = 0.000\n",
    "gbm_table['Test'] = 0.000\n",
    "gbm_table['OOT'] = 0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "deluxe-method",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:26:27.210923Z",
     "start_time": "2021-03-18T10:36:29.027908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49min 47s, sys: 9.24 s, total: 49min 56s\n",
      "Wall time: 49min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a for loop to calculate all GBM FDR@3%\n",
    "\n",
    "# using KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "num_tree = [100,200,500]\n",
    "max_depth = [1,2]\n",
    "learn_rate = [0.1, 0.01]\n",
    "\n",
    "for lr in learn_rate:\n",
    "    for md in max_depth:\n",
    "        for num in num_tree:\n",
    "            for train_index, test_index in kf.split(X):\n",
    "                X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "                y_train, y_test = y.iloc[train_index, :].values.ravel(), y.iloc[test_index, :].values.ravel()\n",
    "                \n",
    "                gbm = GradientBoostingClassifier(learning_rate=lr, n_estimators =num, max_depth=md)\n",
    "                gbm.fit(X_train,y_train)\n",
    "                \n",
    "                gbm_table.loc[(gbm_table['# of Trees']==num)\\\n",
    "                              &(gbm_table['Max Depth']==md)\\\n",
    "                              &(gbm_table['Learning Rate']==lr),'Train'] += fdr_cal(X_train, y_train, gbm)\n",
    "                gbm_table.loc[(gbm_table['# of Trees']==num)\\\n",
    "                              &(gbm_table['Max Depth']==md)\\\n",
    "                              &(gbm_table['Learning Rate']==lr),'Test']+= fdr_cal(X_test, y_test, gbm)\n",
    "                gbm_table.loc[(gbm_table['# of Trees']==num)\\\n",
    "                              &(gbm_table['Max Depth']==md)\\\n",
    "                              &(gbm_table['Learning Rate']==lr),'OOT']+= fdr_cal(oot_x, oot_y, gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "interpreted-gilbert",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:26:27.216824Z",
     "start_time": "2021-03-18T11:26:27.213083Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in ['Train','Test','OOT']:\n",
    "    gbm_table[col] = gbm_table[col]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "adolescent-facing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:26:27.236989Z",
     "start_time": "2021-03-18T11:26:27.219079Z"
    }
   },
   "outputs": [],
   "source": [
    "gbm_table.to_excel('gbm_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "unusual-cookbook",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:26:27.248937Z",
     "start_time": "2021-03-18T11:26:27.238906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># of Trees</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.552788</td>\n",
       "      <td>0.551412</td>\n",
       "      <td>0.524895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.552592</td>\n",
       "      <td>0.551775</td>\n",
       "      <td>0.524644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.553315</td>\n",
       "      <td>0.552598</td>\n",
       "      <td>0.525901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.557247</td>\n",
       "      <td>0.556420</td>\n",
       "      <td>0.530260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.562827</td>\n",
       "      <td>0.559571</td>\n",
       "      <td>0.535624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.570096</td>\n",
       "      <td>0.567215</td>\n",
       "      <td>0.546689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.481384</td>\n",
       "      <td>0.480930</td>\n",
       "      <td>0.462280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.496044</td>\n",
       "      <td>0.495115</td>\n",
       "      <td>0.475021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.544409</td>\n",
       "      <td>0.542764</td>\n",
       "      <td>0.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.497825</td>\n",
       "      <td>0.497089</td>\n",
       "      <td>0.480386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.542634</td>\n",
       "      <td>0.540813</td>\n",
       "      <td>0.518106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.551157</td>\n",
       "      <td>0.549236</td>\n",
       "      <td>0.523303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # of Trees Max Depth Learning Rate     Train      Test       OOT\n",
       "0         100         1           0.1  0.552788  0.551412  0.524895\n",
       "1         200         1           0.1  0.552592  0.551775  0.524644\n",
       "2         500         1           0.1  0.553315  0.552598  0.525901\n",
       "3         100         2           0.1  0.557247  0.556420  0.530260\n",
       "4         200         2           0.1  0.562827  0.559571  0.535624\n",
       "5         500         2           0.1  0.570096  0.567215  0.546689\n",
       "6         100         1          0.01  0.481384  0.480930  0.462280\n",
       "7         200         1          0.01  0.496044  0.495115  0.475021\n",
       "8         500         1          0.01  0.544409  0.542764  0.517100\n",
       "9         100         2          0.01  0.497825  0.497089  0.480386\n",
       "10        200         2          0.01  0.542634  0.540813  0.518106\n",
       "11        500         2          0.01  0.551157  0.549236  0.523303"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-sigma",
   "metadata": {},
   "source": [
    "### FDR@3% Calculation (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table to store the data\n",
    "rfc_table = pd.DataFrame(columns=['# of Trees', 'Max Depth', 'Min Samples Leaf'])\n",
    "num_tree = [50,100,200]\n",
    "max_depth = [5,10]\n",
    "min_leaf = 3\n",
    "\n",
    "\n",
    "i=0\n",
    "for md in max_depth:\n",
    "    for num in num_tree:\n",
    "        rfc_table.loc[i,'# of Trees'] = num\n",
    "        rfc_table.loc[i,'Max Depth'] = md\n",
    "        rfc_table.loc[i,'Min Samples Leaf'] = min_leaf\n",
    "        i+=1\n",
    "\n",
    "rfc_table['Train'] = 0.000\n",
    "rfc_table['Test'] = 0.000\n",
    "rfc_table['OOT'] = 0.000\n",
    "rfc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create a for loop to calculate all GBM FDR@3%\n",
    "\n",
    "# using KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "num_tree = [50,100,200]\n",
    "max_depth = [5,10]\n",
    "min_leaf = 3\n",
    "\n",
    "for md in max_depth:\n",
    "    for num in num_tree:\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "            y_train, y_test = y.iloc[train_index, :].values.ravel(), y.iloc[test_index, :].values.ravel()\n",
    "\n",
    "            rfc = RandomForestClassifier(n_estimators =num, max_depth=md, min_samples_leaf=min_leaf)\n",
    "            rfc.fit(X_train,y_train)\n",
    "\n",
    "            rfc_table.loc[(rfc_table['# of Trees']==num)\\\n",
    "                          &(rfc_table['Max Depth']==md),\\\n",
    "                          'Train'] += fdr_cal(X_train, y_train, rfc)\n",
    "            rfc_table.loc[(rfc_table['# of Trees']==num)\\\n",
    "                          &(rfc_table['Max Depth']==md),\\\n",
    "                          'Test']+= fdr_cal(X_test, y_test, rfc)\n",
    "            rfc_table.loc[(rfc_table['# of Trees']==num)\\\n",
    "                          &(rfc_table['Max Depth']==md),\\\n",
    "                          'OOT']+= fdr_cal(oot_x, oot_y, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Train','Test','OOT']:\n",
    "    rfc_table[col] = rfc_table[col]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc_table.to_excel('rfc_table.xlsx')\n",
    "rfc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table to store the data\n",
    "mlp_table = pd.DataFrame(columns=['Node', 'Epoch', 'Layer'])\n",
    "nodes = [10,30,40]\n",
    "max_iter = [20, 50]\n",
    "layer = 1\n",
    "\n",
    "\n",
    "i=0\n",
    "for mi in max_iter:\n",
    "    for node in nodes:\n",
    "        mlp_table.loc[i,'Node'] = node\n",
    "        mlp_table.loc[i,'Epoch'] = mi\n",
    "        mlp_table.loc[i,'Layer'] = layer\n",
    "        i+=1\n",
    "\n",
    "mlp_table['Train'] = 0.000\n",
    "mlp_table['Test'] = 0.000\n",
    "mlp_table['OOT'] = 0.000\n",
    "mlp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create a for loop to calculate all GBM FDR@3%\n",
    "\n",
    "# using KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "nodes = [10,30,40]\n",
    "max_iter = [20, 50]\n",
    "layer = 1\n",
    "\n",
    "for mi in max_iter:\n",
    "    for node in nodes:\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "            y_train, y_test = y.iloc[train_index, :].values.ravel(), y.iloc[test_index, :].values.ravel()\n",
    "\n",
    "            mlp = MLPClassifier(max_iter=mi, hidden_layer_sizes=(node,))\n",
    "            mlp.fit(X_train,y_train)\n",
    "\n",
    "            mlp_table.loc[(mlp_table['Node']==node)\\\n",
    "                          &(mlp_table['Epoch']==mi),\\\n",
    "                          'Train'] += fdr_cal(X_train, y_train, mlp)\n",
    "            mlp_table.loc[(mlp_table['Node']==node)\\\n",
    "                          &(mlp_table['Epoch']==mi),\\\n",
    "                          'Test']+= fdr_cal(X_test, y_test, mlp)\n",
    "            mlp_table.loc[(mlp_table['Node']==node)\\\n",
    "                          &(mlp_table['Epoch']==mi),\\\n",
    "                          'OOT']+= fdr_cal(oot_x, oot_y, mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-terror",
   "metadata": {},
   "source": [
    "LogReg: 3 min\n",
    "Random Forest: 14 min\n",
    "Neural Net: 30 min\n",
    "Gradient Boosting: 50 min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
